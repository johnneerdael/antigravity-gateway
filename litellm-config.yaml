model_list:
  # Claude models
  - model_name: claude-sonnet-4-5-thinking
    model_info:
      mode: chat
      supports_vision: true
      supports_function_calling: true
      supports_parallel_function_calling: true
      max_input_tokens: 200000
      max_output_tokens: 16000
    litellm_params:
      model: openai/claude-sonnet-4-5-thinking
      api_base: http://antigravity-gateway:8080/v1
      api_key: "not-needed"
      stream: true

  - model_name: claude-opus-4-5-thinking
    model_info:
      mode: chat
      supports_vision: true
      supports_function_calling: true
      supports_parallel_function_calling: true
      max_input_tokens: 200000
      max_output_tokens: 16000
    litellm_params:
      model: openai/claude-opus-4-5-thinking
      api_base: http://antigravity-gateway:8080/v1
      api_key: "not-needed"
      stream: true

  - model_name: claude-sonnet-4-5
    model_info:
      mode: chat
      supports_vision: true
      supports_function_calling: true
      supports_parallel_function_calling: true
      max_input_tokens: 200000
      max_output_tokens: 8192
    litellm_params:
      model: openai/claude-sonnet-4-5
      api_base: http://antigravity-gateway:8080/v1
      api_key: "not-needed"
      stream: true

  # Gemini 3 models
  - model_name: gemini-3-flash
    model_info:
      mode: chat
      supports_vision: true
      supports_function_calling: true
      supports_parallel_function_calling: true
      max_input_tokens: 1048576
      max_output_tokens: 16384
    litellm_params:
      model: openai/gemini-3-flash
      api_base: http://antigravity-gateway:8080/v1
      api_key: "not-needed"
      stream: true

  - model_name: gemini-3-pro-high
    model_info:
      mode: chat
      supports_vision: true
      supports_function_calling: true
      supports_parallel_function_calling: true
      max_input_tokens: 1048576
      max_output_tokens: 16384
    litellm_params:
      model: openai/gemini-3-pro-high
      api_base: http://antigravity-gateway:8080/v1
      api_key: "not-needed"
      stream: true

  - model_name: gemini-3-pro-low
    model_info:
      mode: chat
      supports_vision: true
      supports_function_calling: true
      supports_parallel_function_calling: true
      max_input_tokens: 1048576
      max_output_tokens: 16384
    litellm_params:
      model: openai/gemini-3-pro-low
      api_base: http://antigravity-gateway:8080/v1
      api_key: "not-needed"
      stream: true

  - model_name: gemini-3-pro-image
    model_info:
      mode: chat
      supports_vision: true
      supports_function_calling: true
      supports_parallel_function_calling: true
      max_input_tokens: 1048576
      max_output_tokens: 16384
    litellm_params:
      model: openai/gemini-3-pro-image
      api_base: http://antigravity-gateway:8080/v1
      api_key: "not-needed"
      stream: true

  # Gemini 2.5 models
  - model_name: gemini-2.5-pro
    model_info:
      mode: chat
      supports_vision: true
      supports_function_calling: true
      supports_parallel_function_calling: true
      max_input_tokens: 1048576
      max_output_tokens: 16384
    litellm_params:
      model: openai/gemini-2.5-pro
      api_base: http://antigravity-gateway:8080/v1
      api_key: "not-needed"
      stream: true

  - model_name: gemini-2.5-flash
    model_info:
      mode: chat
      supports_vision: true
      supports_function_calling: true
      supports_parallel_function_calling: true
      max_input_tokens: 1048576
      max_output_tokens: 16384
    litellm_params:
      model: openai/gemini-2.5-flash
      api_base: http://antigravity-gateway:8080/v1
      api_key: "not-needed"
      stream: true

  - model_name: gemini-2.5-flash-thinking
    model_info:
      mode: chat
      supports_vision: true
      supports_function_calling: true
      supports_parallel_function_calling: true
      max_input_tokens: 1048576
      max_output_tokens: 16384
    litellm_params:
      model: openai/gemini-2.5-flash-thinking
      api_base: http://antigravity-gateway:8080/v1
      api_key: "not-needed"
      stream: true

  - model_name: gemini-2.5-flash-lite
    model_info:
      mode: chat
      supports_vision: true
      supports_function_calling: true
      supports_parallel_function_calling: true
      max_input_tokens: 1048576
      max_output_tokens: 8192
    litellm_params:
      model: openai/gemini-2.5-flash-lite
      api_base: http://antigravity-gateway:8080/v1
      api_key: "not-needed"
      stream: true
